# Perceptron
Supervised classification of an input into one of several possible non-binary outputs. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time.

-----------------------------------------------------------------------------------------------------------------------------
Developed discriminative classifier and applied it to two NLP sequence labeling tasks: part-of-speech tagging and named entity recognition. 

##Files:##
1. PART 1

__perceplearn.py__
Command: python3 perceplearn.py TRAININGFILE MODELFILE

where
TRAININGFILE: input:training file labeled with classes for each example.1 line represents 1 example
MODELFILE: modelfile is the output 
(Prints to stdout after each iteration,the iteration no, previous error and error calculated on training set.)

__percepclassify.py__
Command: python3 percepclassify.py MODELFILE

where
MODELFILE: modelfile is the output 
Takes its input from STDIN. Outputs predicted class to STDOUT immediately after each corresponding line is entered via STDIN.

1. PART 2
DIRECTORY:postagging

__postrain.py__
Command:python3 postrain.py TRAININGFILE MODEL

where 
TRAININGFILE is the input file formated with one sentence per line, and each sentence composed of word/tag pairs. For example, a small training file might contain these lines:
This/DT is/VBZ a/DT test/NN ./.
I/PRP saw/VBD a/DT movie/NN ./.
I/PRP like/VBP cookies/NNS ./.

MODELFILE is the output file containing the model.

(Uses perceplearn through importing module to train the model )

__postag.py__
Command:python3 postag.py MODEL

where 
MODEL is the model generated by postrain.

postag takes its input from STDIN in the form of one sentence per line, where each sentence is a sequence of words (without tags). Output is written to STDOUT, and is a tagged sentence (in the same format as the training data) for each input sentence.

1. PART 3 : Averaged perceptron to perform named entity recogntion.
directory:ner

__nelearn.py__

Command:python3 nelearn.py TRAININGFILE MODEL

__netag.py__
Command:python3 netag.py MODEL
-----------------------------------------------------------------------------------

###  Accuracy of part-of-speech tagger: ###
__95.56%__

###  Precision, recall and F-score for each of the named entity types for named entity recognizer, and the overall F-score: ###

	Precision     	      | Recall	     		 	        | F-score

	MISC 0.73584905660377 |  0.350561797752809              |0.4748

	PER 0.9136316337148803|  0.7184942716857611             |0.80439

	ORG 0.8391070053887606|  0.6411764705882353             |0.727

	LOC 0.9461942257217848|  0.7327235772357723             |0.8259
__Overall Fscore: 0.7504 __

###   What happens if you use your Naive Bayes classifier instead of your perceptron classifier (report performance metrics)? Why do you think that is? ###
With Naive Bayes:POS:93.1%
Reason: 
1)Naive Bayes basic assumption is that the words are independent. Here in part-of-speech tagging and named entity classification, we use the context of the words. Therefore the tags depend on the structure of surrounding words. 
2)The number of iterations Hence Naive Bayes does not perform better.


